{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lenet框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 3)\n",
    "max1 = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(6, 16, 5)\n",
    "max2 = nn.MaxPool2d(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 30, 30])\n",
      "torch.Size([1, 6, 15, 15])\n",
      "torch.Size([1, 16, 11, 11])\n",
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "out1 = conv1(torch.ones(1,1,32,32))\n",
    "print(out1.shape)\n",
    "out2 = max1(out1)\n",
    "print(out2.shape)\n",
    "out3 = conv2(out2)\n",
    "print(out3.shape)\n",
    "out4 = max1(out3)\n",
    "print(out4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride=4, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 96, out_channels = 256 , kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size= 3,stride=2,padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels= 256, out_channels= 384,kernel_size= 3,stride=1,padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384,out_channels= 384,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=384,out_channels= 256,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
    "        self.fc1   = nn.Linear(5*5*256,4096)\n",
    "        self.fc2   = nn.Linear(4096,4096)\n",
    "        self.fc3   = nn.Linear(4096,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool3(F.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet(2)\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels = 3, out_channels = 96, kernel_size = 11, stride=4, padding=0)\n",
    "pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "conv2 = nn.Conv2d(in_channels = 96, out_channels = 256 , kernel_size = 5, stride = 1, padding = 2)\n",
    "pool2 = nn.MaxPool2d(kernel_size= 3,stride=2,padding=0)\n",
    "conv3 = nn.Conv2d(in_channels= 256, out_channels= 384,kernel_size= 3,stride=1,padding=1)\n",
    "conv4 = nn.Conv2d(in_channels=384,out_channels= 384,kernel_size=3,stride=1,padding=1)\n",
    "conv5 = nn.Conv2d(in_channels=384,out_channels= 256,kernel_size=3,stride=1,padding=1)\n",
    "pool3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 96, 48, 48])\n",
      "torch.Size([4, 96, 23, 23])\n",
      "torch.Size([4, 256, 23, 23])\n",
      "torch.Size([4, 256, 11, 11])\n",
      "torch.Size([4, 384, 11, 11])\n",
      "torch.Size([4, 384, 11, 11])\n",
      "torch.Size([4, 256, 11, 11])\n",
      "torch.Size([4, 256, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "out = conv1(torch.ones(4,3,200,200))\n",
    "print(out.shape)\n",
    "out = pool1(out)\n",
    "print(out.shape)\n",
    "out = conv2(out)\n",
    "print(out.shape)\n",
    "out = pool2(out)\n",
    "print(out.shape)\n",
    "out = conv3(out)\n",
    "print(out.shape)\n",
    "out = conv4(out)\n",
    "print(out.shape)\n",
    "out = conv5(out)\n",
    "print(out.shape)\n",
    "out = pool3(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_1 = nn.Conv2d(3, 64, 3) # 64 * 222 * 222\n",
    "conv1_2 = nn.Conv2d(64, 64, 3, padding=(1, 1)) # 64 * 222* 222\n",
    "maxpool1 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 64 * 112 * 112\n",
    "\n",
    "conv2_1 = nn.Conv2d(64, 128, 3) # 128 * 110 * 110\n",
    "conv2_2 = nn.Conv2d(128, 128, 3, padding=(1, 1)) # 128 * 110 * 110\n",
    "maxpool2 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 128 * 56 * 56\n",
    "\n",
    "conv3_1 = nn.Conv2d(128, 256, 3) # 256 * 54 * 54\n",
    "conv3_2 = nn.Conv2d(256, 256, 3, padding=(1, 1)) # 256 * 54 * 54\n",
    "conv3_3 = nn.Conv2d(256, 256, 3, padding=(1, 1)) # 256 * 54 * 54\n",
    "maxpool3 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 256 * 28 * 28\n",
    "\n",
    "conv4_1 = nn.Conv2d(256, 512, 3) # 512 * 26 * 26\n",
    "conv4_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 26 * 26\n",
    "conv4_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 26 * 26\n",
    "maxpool4 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 512 * 14 * 14\n",
    "\n",
    "conv5_1 = nn.Conv2d(512, 512, 3) # 512 * 12 * 12\n",
    "conv5_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 12 * 12\n",
    "conv5_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 12 * 12\n",
    "maxpool5 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 512 * 7 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 198, 198])\n",
      "torch.Size([1, 64, 198, 198])\n",
      "torch.Size([1, 64, 100, 100])\n",
      "torch.Size([1, 128, 98, 98])\n",
      "torch.Size([1, 128, 98, 98])\n",
      "torch.Size([1, 128, 50, 50])\n",
      "torch.Size([1, 256, 48, 48])\n",
      "torch.Size([1, 256, 48, 48])\n",
      "torch.Size([1, 256, 48, 48])\n",
      "torch.Size([1, 256, 25, 25])\n",
      "torch.Size([1, 512, 23, 23])\n",
      "torch.Size([1, 512, 23, 23])\n",
      "torch.Size([1, 512, 23, 23])\n",
      "torch.Size([1, 512, 12, 12])\n",
      "torch.Size([1, 512, 10, 10])\n",
      "torch.Size([1, 512, 10, 10])\n",
      "torch.Size([1, 512, 10, 10])\n",
      "torch.Size([1, 512, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "out = conv1_1(torch.ones(1,3,200,200))\n",
    "print(out.shape)\n",
    "out = conv1_2(out)\n",
    "print(out.shape)\n",
    "out = maxpool1(out)\n",
    "print(out.shape)\n",
    "out = conv2_1(out)\n",
    "print(out.shape)\n",
    "out = conv2_2(out)\n",
    "print(out.shape)\n",
    "out = maxpool2(out)\n",
    "print(out.shape)\n",
    "out = conv3_1(out)\n",
    "print(out.shape)\n",
    "out = conv3_2(out)\n",
    "print(out.shape)\n",
    "out = conv3_3(out)\n",
    "print(out.shape)\n",
    "out = maxpool3(out)\n",
    "print(out.shape)\n",
    "out = conv4_1(out)\n",
    "print(out.shape)\n",
    "out = conv4_2(out)\n",
    "print(out.shape)\n",
    "out = conv4_3(out)\n",
    "print(out.shape)\n",
    "out = maxpool4(out)\n",
    "print(out.shape)\n",
    "out = conv5_1(out)\n",
    "print(out.shape)\n",
    "out = conv5_2(out)\n",
    "print(out.shape)\n",
    "out = conv5_3(out)\n",
    "print(out.shape)\n",
    "out = maxpool5(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxpool5 = nn.MaxPool2d(kernel_size=2, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "out = maxpool5(torch.ones(1,128,50,50))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        self.features =  nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "out = vgg.features(torch.ones(1,3,200,200))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(in_channel,out_channel, kernel, stride=1, padding=0):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Conv2d(in_channel, out_channel, kernel, stride, padding),\n",
    "        nn.BatchNorm2d(out_channel, eps=1e-3),\n",
    "        nn.ReLU(True)\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class inception(nn.Module):\n",
    "    def __init__(self, in_channel, out1_1,out2_1, out2_3, out3_1, out3_5,out4_1):\n",
    "        super(inception, self).__init__()\n",
    "        \n",
    "        # 定义inception模块第一条线路\n",
    "        self.branch1x1 = conv_relu(in_channel,out1_1, 1)\n",
    "        \n",
    "        # 定义inception模块第二条线路\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            conv_relu(in_channel, out2_1, 1),\n",
    "            conv_relu(out2_1, out2_3, 3, padding=1)\n",
    "        )\n",
    "        \n",
    "        #定义inception模块的第三条线路\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            conv_relu(in_channel, out3_1, 1),\n",
    "            conv_relu(out3_1, out3_5, 5, padding=2)\n",
    "        )\n",
    "        \n",
    "        # 定义inception模块第四条线路\n",
    "        \n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            conv_relu(in_channel, out4_1,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        f1 = self.branch1x1(x)\n",
    "        print(f1.shape)\n",
    "        f2 = self.branch3x3(x)\n",
    "        print(f2.shape)\n",
    "        f3 = self.branch5x5(x)\n",
    "        print(f3.shape)\n",
    "        f4 = self.branch_pool(x)\n",
    "        print(f4.shape)\n",
    "        \n",
    "        output = torch.cat((f1, f2, f3, f4), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : 3 x 200 x 200\n",
      "torch.Size([1, 64, 200, 200])\n",
      "torch.Size([1, 64, 200, 200])\n",
      "torch.Size([1, 96, 200, 200])\n",
      "torch.Size([1, 32, 200, 200])\n",
      "output shape : 256 x 200 x 200\n"
     ]
    }
   ],
   "source": [
    "test_net = inception(3, 64, 48, 64, 64, 96, 32)\n",
    "test_x = Variable(torch.zeros(1, 3, 200, 200))\n",
    "print('input shape : {} x {} x {}'.format(test_x.shape[1], test_x.shape[2],test_x.shape[3]))\n",
    "test_y = test_net(test_x)\n",
    "print('output shape : {} x {} x {}'.format(test_y.shape[1], test_y.shape[2], test_y.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class googlenet(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes, verbose=False):\n",
    "        super(googlenet, self).__init__()\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            conv_relu(in_channel, out_channel=64, kernel=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            conv_relu(64, 64, kernel=1),\n",
    "            conv_relu(64, 192, kernel=3, padding=1),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            inception(192, 64, 96, 128, 16, 32, 32),\n",
    "            inception(256, 128, 128, 192, 32, 96, 64),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            inception(480, 192, 96, 208, 16, 48, 64),\n",
    "            inception(512, 160, 112, 224, 24, 64, 64),\n",
    "            inception(512, 128, 128, 256, 24, 64, 64),\n",
    "            inception(512, 112, 144, 288, 32, 64, 64),\n",
    "            inception(528, 256, 160, 320, 32, 128, 128),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            inception(832, 256, 160, 320, 32, 128, 128),\n",
    "            inception(832, 384, 182, 384, 48, 128, 128),\n",
    "            nn.AvgPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(1024*2*2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        if self.verbose:\n",
    "            print('block 1 output: {}'.format(x.shape))\n",
    "        x = self.block2(x)\n",
    "        if self.verbose:\n",
    "            print('block 2 output: {}'.format(x.shape))\n",
    "        x = self.block3(x)\n",
    "        if self.verbose:\n",
    "            print('block 3 output: {}'.format(x.shape))\n",
    "        x = self.block4(x)\n",
    "        if self.verbose:\n",
    "            print('block 4 output: {}'.format(x.shape))\n",
    "        x = self.block5(x)\n",
    "        if self.verbose:\n",
    "            print('block 5 output: {}'.format(x.shape))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 1 output: torch.Size([1, 64, 49, 49])\n",
      "block 2 output: torch.Size([1, 192, 24, 24])\n",
      "torch.Size([1, 64, 24, 24])\n",
      "torch.Size([1, 128, 24, 24])\n",
      "torch.Size([1, 32, 24, 24])\n",
      "torch.Size([1, 32, 24, 24])\n",
      "torch.Size([1, 128, 24, 24])\n",
      "torch.Size([1, 192, 24, 24])\n",
      "torch.Size([1, 96, 24, 24])\n",
      "torch.Size([1, 64, 24, 24])\n",
      "block 3 output: torch.Size([1, 480, 11, 11])\n",
      "torch.Size([1, 192, 11, 11])\n",
      "torch.Size([1, 208, 11, 11])\n",
      "torch.Size([1, 48, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 160, 11, 11])\n",
      "torch.Size([1, 224, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 128, 11, 11])\n",
      "torch.Size([1, 256, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 112, 11, 11])\n",
      "torch.Size([1, 288, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 64, 11, 11])\n",
      "torch.Size([1, 256, 11, 11])\n",
      "torch.Size([1, 320, 11, 11])\n",
      "torch.Size([1, 128, 11, 11])\n",
      "torch.Size([1, 128, 11, 11])\n",
      "block 4 output: torch.Size([1, 832, 5, 5])\n",
      "torch.Size([1, 256, 5, 5])\n",
      "torch.Size([1, 320, 5, 5])\n",
      "torch.Size([1, 128, 5, 5])\n",
      "torch.Size([1, 128, 5, 5])\n",
      "torch.Size([1, 384, 5, 5])\n",
      "torch.Size([1, 384, 5, 5])\n",
      "torch.Size([1, 128, 5, 5])\n",
      "torch.Size([1, 128, 5, 5])\n",
      "block 5 output: torch.Size([1, 1024, 2, 2])\n",
      "output: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "test_net = googlenet(3, 2, True)\n",
    "test_x = Variable(torch.zeros(1, 3, 200, 200))\n",
    "test_y = test_net(test_x)\n",
    "print('output: {}'.format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ResNet（残差网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''ResNet-18 Image classfication for cifar-10 with PyTorch \n",
    "\n",
    "Author 'Sun-qian'.\n",
    "\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512*6*6, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        print(out.shape)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18()\n",
    "outputs = net(torch.zeros(1, 3, 200, 200))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
